{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tMOK-4ThP1w"
      },
      "outputs": [],
      "source": [
        "import sys, os\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "project_dir = \"/content/drive/MyDrive/mlb-project-data\"\n",
        "data_path = f\"{project_dir}/model_ready_data.parquet\"\n",
        "\n",
        "if os.path.exists(data_path):\n",
        "    df_train = pd.read_parquet(data_path)\n",
        "    print(f\"Loaded {len(df_train)} rows for modeling.\")\n",
        "else:\n",
        "    print(\"Data not found. Run Notebook 2 first.\")\n",
        "\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import brier_score_loss, accuracy_score, log_loss\n",
        "from sklearn.calibration import calibration_curve"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "id": "7g04zlq3x2dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_cols = [\n",
        "    'rest_days',\n",
        "    'log5_prob',\n",
        "    'rolling_10_runs_scored',\n",
        "    'rolling_10_runs_allowed',\n",
        "    'rolling_10_hits',\n",
        "    'rolling_10_errors',\n",
        "    'rolling_pythag_win_pct',\n",
        "    'opp_pythag_win_pct',\n",
        "    'team_code',\n",
        "    'opponent_code',\n",
        "    'is_home'\n",
        "]\n",
        "df_train = df_train.sort_values(['date', 'team']).reset_index(drop=True)\n",
        "\n",
        "X = df_train[feature_cols]\n",
        "\n",
        "y = df_train['result']\n",
        "\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "print(f\"Features configured: {len(feature_cols)}\")\n",
        "print(f\"Splitter configured: 5-Fold Time Series\")"
      ],
      "metadata": {
        "id": "h8NhLKauvqUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- CROSS VALIDATION PLAN ---\")\n",
        "for split_idx, (train_index, test_index) in enumerate(tscv.split(X)):\n",
        "    train_dates = df_train.iloc[train_index]['date']\n",
        "    test_dates = df_train.iloc[test_index]['date']\n",
        "\n",
        "    print(f\"Split {split_idx + 1}:\")\n",
        "    print(f\"  Train: {train_dates.min().date()} -> {train_dates.max().date()} ({len(train_index)} games)\")\n",
        "    print(f\"  Test:  {test_dates.min().date()} -> {test_dates.max().date()} ({len(test_index)} games)\")\n",
        "    print(\"-\" * 30)"
      ],
      "metadata": {
        "id": "EmQ5gq9fwF19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "all_predictions = []\n",
        "all_actuals = []\n",
        "all_dates = []\n",
        "\n",
        "model = make_pipeline(SimpleImputer(strategy='mean'),StandardScaler(), LogisticRegression())\n",
        "\n",
        "print(\"Starting Time-Series Training Loop...\")\n",
        "\n",
        "for split_idx, (train_index, test_index) in enumerate(tscv.split(X)):\n",
        "\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    probs = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    all_predictions.extend(probs)\n",
        "    all_actuals.extend(y_test)\n",
        "    all_dates.extend(df_train.iloc[test_index]['date'])\n",
        "\n",
        "    acc = accuracy_score(y_test, (probs > 0.5).astype(int))\n",
        "    print(f\"  Split {split_idx + 1}: Accuracy = {acc:.3f}\")\n",
        "\n",
        "print(\"Training Loop Complete.\")"
      ],
      "metadata": {
        "id": "TxbiuSCM2YD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.isna().sum())"
      ],
      "metadata": {
        "id": "Sd9hvaM63mYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_step = model.named_steps['logisticregression']\n",
        "coeffs = pd.DataFrame({\n",
        "    'Feature': feature_cols,\n",
        "    'Weight': model_step.coef_[0]\n",
        "}).sort_values('Weight', ascending=False)\n",
        "\n",
        "print(\"--- WHAT DID THE MODEL LEARN? ---\")\n",
        "print(coeffs)\n",
        "\n",
        "prob_true, prob_pred = calibration_curve(all_actuals, all_predictions, n_bins=10)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', label='Perfect Calibration')\n",
        "plt.plot(prob_pred, prob_true, marker='.', label='Your Model')\n",
        "plt.xlabel('Predicted Probability')\n",
        "plt.ylabel('Actual Win Percentage')\n",
        "plt.title('Calibration Curve: Does 60% mean 60%?')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rmBiywNMEXCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "X_raw = df_train[feature_cols].values\n",
        "y_train_final = df_train['result'].values\n",
        "\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_imputed = imputer.fit_transform(X_raw)\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "print(f\"Original shape: {X_raw.shape}\")\n",
        "print(f\"Processed shape: {X_scaled.shape}\")\n",
        "print(f\"Any NaNs left? {np.isnan(X_scaled).sum()}\")"
      ],
      "metadata": {
        "id": "LbxHUyfsHeQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pymc as pm\n",
        "import arviz as az\n",
        "\n",
        "X_train_final = X_scaled\n",
        "\n",
        "print(f\"Training Bayesian Model on {len(X_train_final)} games...\")\n",
        "\n",
        "with pm.Model() as bayesian_model:\n",
        "    alpha = pm.Normal(\"alpha\", mu=0, sigma=1)\n",
        "\n",
        "    betas = pm.Normal(\"betas\", mu=0, sigma=1, shape=X_train_final.shape[1])\n",
        "\n",
        "    mu = alpha + pm.math.dot(X_train_final, betas)\n",
        "\n",
        "    theta = pm.math.sigmoid(mu)\n",
        "\n",
        "    y_obs = pm.Bernoulli(\"y_obs\", p=theta, observed=y_train_final)\n",
        "\n",
        "    print(\"Thinking (Sampling)... this might take 2-3 minutes...\")\n",
        "    trace = pm.sample(1000, tune=1000, chains=2, return_inferencedata=True)\n",
        "\n",
        "print(\"Bayesian Model Trained!\")"
      ],
      "metadata": {
        "id": "MlwNP_19GJbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "az.plot_forest(trace, var_names=[\"betas\"], combined=True, figsize=(10, 6))\n",
        "\n",
        "plt.yticks(\n",
        "    ticks=range(len(feature_cols)),\n",
        "    labels=reversed(feature_cols)\n",
        "plt.title(\"Bayesian Feature Weights (94% Credible Interval)\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.xlabel(\"Impact on Winning (Negative <---> Positive)\")\n",
        "plt.axvline(0, color='red', linestyle='--')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0HBrUE1zQYAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "az.plot_trace(trace, var_names=[\"alpha\", \"betas\"], compact=True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "summary = az.summary(trace, var_names=[\"alpha\", \"betas\"])\n",
        "\n",
        "summary_betas = summary[summary.index.str.contains(\"betas\")].copy()\n",
        "summary_betas['Feature'] = feature_cols\n",
        "\n",
        "print(\"Bayesian feature importance:\")\n",
        "print(summary_betas[['Feature', 'mean', 'sd', 'r_hat']].sort_values('mean', ascending=False))"
      ],
      "metadata": {
        "id": "v7iojv-kTuo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with bayesian_model:\n",
        "    ppc = pm.sample_posterior_predictive(trace, var_names=[\"y_obs\"])\n",
        "\n",
        "bayesian_probs = ppc.posterior_predictive['y_obs'].mean(dim=[\"chain\", \"draw\"]).values\n",
        "\n",
        "df_simulation = df_train.copy()\n",
        "df_simulation['my_prob'] = bayesian_probs\n",
        "\n",
        "print(f\"Generated predictions for {len(df_simulation)} games.\")\n",
        "print(df_simulation[['date', 'team', 'opponent', 'my_prob', 'result']].head())"
      ],
      "metadata": {
        "id": "QUMQpcpYUemz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simulate_betting(df, threshold=0.05, stake=100):\n",
        "\n",
        "    sim = df.copy()\n",
        "\n",
        "    def us_odds_to_prob(odds):\n",
        "        if pd.isna(odds): return np.nan\n",
        "        if odds > 0:\n",
        "            return 100 / (odds + 100)\n",
        "        else:\n",
        "            return (-odds) / (-odds + 100)\n",
        "\n",
        "    sim['vegas_prob'] = sim['moneyline_closing'].apply(us_odds_to_prob)\n",
        "\n",
        "    sim['edge'] = sim['my_prob'] - sim['vegas_prob']\n",
        "\n",
        "    sim['bet_placed'] = sim['edge'] > threshold\n",
        "\n",
        "    def calculate_pnl(row):\n",
        "        if not row['bet_placed']: return 0\n",
        "\n",
        "        if row['moneyline_closing'] > 0:\n",
        "            decimal_odds = 1 + (row['moneyline_closing'] / 100)\n",
        "        else:\n",
        "            decimal_odds = 1 + (100 / -row['moneyline_closing'])\n",
        "\n",
        "        if row['result'] == 1:\n",
        "            return stake * (decimal_odds - 1)\n",
        "        else:\n",
        "            return -stake\n",
        "\n",
        "    sim['pnl'] = sim.apply(calculate_pnl, axis=1)\n",
        "    sim['bankroll'] = sim['pnl'].cumsum()\n",
        "\n",
        "    return sim\n",
        "\n",
        "results = simulate_betting(df_simulation, threshold=0.05)\n",
        "\n",
        "total_bets = results['bet_placed'].sum()\n",
        "total_profit = results['pnl'].sum()\n",
        "roi = (total_profit / (total_bets * 100)) * 100 if total_bets > 0 else 0\n",
        "\n",
        "print(f\"--- BETTING SIMULATION RESULTS ---\")\n",
        "print(f\"Total Bets Placed: {total_bets}\")\n",
        "print(f\"Total Profit: ${total_profit:.2f}\")\n",
        "print(f\"ROI: {roi:.2f}%\")\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(results[results['bet_placed']]['date'], results[results['bet_placed']]['bankroll'])\n",
        "plt.title(f\"Bankroll Simulation (Threshold=5%) - Profit: ${total_profit:.0f}\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Profit ($)\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v2DRXfRdVFQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vfGDNBvPaRRi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}